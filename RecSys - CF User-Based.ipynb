{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>User-Based Collaborative Filtering</h1>\n",
    "A recommender that is based on the user-based collaborative filtering approach.\n",
    "\n",
    "The recommender system will perform the following steps:\n",
    "1. Retrieve item and activity data\n",
    "2. Build the recommendation engine\n",
    "3. Generate recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 1 - Retrieve Data</h2>\n",
    "The first step would always be to gather the data and pull it into the programming environment.\n",
    "For our use case, we download the MovieLens dataset containing three sets of data,\n",
    "\n",
    "- Movie data containing a certain movie's information, such as movieID, release date, URL, genre details, and so on\n",
    "- User data containing the user information, such as userID, age, gender, occupation, ZIP code, and so on\n",
    "- Ratings data containing userID, itemID, rating, timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries that are going to be used here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column headers for the dataset\n",
    "data_cols = ['user id','movie id','rating','timestamp']\n",
    "item_cols = ['movie id','movie title','release date', 'video release date','IMDb URL','unknown','Action', 'Adventure','Animation','Childrens','Comedy','Crime', 'Documentary','Drama','Fantasy','Film-Noir','Horror', 'Musical','Mystery','Romance ','Sci-Fi','Thriller', 'War' ,'Western']\n",
    "user_cols = ['user id','age','gender','occupation', 'zip code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User activity data\n",
    "df_u_data = pd.read_csv('/home/nbuser/library/dataset/u.data', header=None, sep='\\t', names=data_cols, encoding='latin-1')\n",
    "df_u_data = df_u_data.sort_values('user id', ascending=1)\n",
    "df_u_data.columns\n",
    "df_u_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of movie items\n",
    "df_u_item = pd.read_csv('/home/nbuser/library/dataset/u.item', header=None, sep='|', names=item_cols, encoding='latin-1')\n",
    "df_u_item = df_u_item.sort_values('movie id', ascending=1)\n",
    "df_u_item.columns\n",
    "df_u_item.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 2 - Build Recommendation Engine</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.merge(df_u_item, df_u_data)\n",
    "\n",
    "ratings.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll pivot this table to construct a nice matrix of users and the movies they rated. NaN indicates missing data, or movies that a given user did not watch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userRatings = ratings.pivot_table(index=['user id'], columns=['movie title'], values='rating')\n",
    "userRatings.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the magic happens - pandas has a built-in corr() method that will compute a correlation score for every column pair in the matrix! This gives us a correlation score between every pair of movies (where at least one user rated both movies - otherwise NaN's will show up.) That's amazing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMatrix = userRatings.corr()\n",
    "corrMatrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we want to avoid spurious results that happened from just a handful of users that happened to rate the same pair of movies. In order to restrict our results to movies that lots of people rated together - and also give us more popular results that are more easily recongnizable - we'll use the min_periods argument to throw out results where fewer than 100 users rated a given movie pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMatrix = userRatings.corr(method='pearson', min_periods=20)\n",
    "corrMatrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 3 - Generate Recommendations</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's produce some movie recommendations for user ID 0, who I manually added to the data set as a test case. This guy really likes Star Wars and The Empire Strikes Back, but hated Gone with the Wind. I'll extract his ratings from the userRatings DataFrame, and use dropna() to get rid of missing data (leaving me only with a Series of the movies I actually rated:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myRatings = userRatings.loc[1].dropna()\n",
    "myRatings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's go through each movie I rated one at a time, and build up a list of possible recommendations based on the movies similar to the ones I rated.\n",
    "\n",
    "So for each movie I rated, I'll retrieve the list of similar movies from our correlation matrix. I'll then scale those correlation scores by how well I rated the movie they are similar to, so movies similar to ones I liked count more than movies similar to ones I hated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simCandidates = pd.Series()\n",
    "for i in range(0, len(myRatings.index)):\n",
    "    print (\"Adding sims for \" + myRatings.index[i] + \"...\")\n",
    "    # Retrieve similar movies to this one that I rated\n",
    "    sims = corrMatrix[myRatings.index[i]].dropna()\n",
    "    # Now scale its similarity by how well I rated this movie\n",
    "    sims = sims.map(lambda x: x * myRatings[i])\n",
    "    # Add the score to the list of similarity candidates\n",
    "    simCandidates = simCandidates.append(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Glance at our results so far:\n",
    "simCandidates.sort_values(inplace = True, ascending = False)\n",
    "simCandidates.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is starting to look like something useful! Note that some of the same movies came up more than once, because they were similar to more than one movie I rated. We'll use groupby() to add together the scores from movies that show up more than once, so they'll count more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simCandidates = simCandidates.groupby(simCandidates.index).sum()\n",
    "simCandidates.sort_values(inplace = True, ascending = False)\n",
    "simCandidates.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
