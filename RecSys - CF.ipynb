{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Import the requisite libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data from the transaction data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in all the records into a data frame\n",
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('ml-100k/u.data', sep='\\t', names=names)\n",
    "\n",
    "# Get the unique user IDs and movie IDs from the transactional data\n",
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "print str(n_users) + 'users'\n",
    "print str(n_items) + 'items'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = np.zeros((n_users, n_items))\n",
    "for row in df.itertuples():\n",
    "    ratings[row[1]-1, row[2]-1] = row[3]\n",
    "    \n",
    "sparsity = float(len(ratings.nonzero()[0]))\n",
    "sparsity /= (ratings.shape[0] * ratings.shape[1])\n",
    "sparsity *= 100\n",
    "print(sparsity)\n",
    "\n",
    "def train_test_split(ratings):\n",
    "    test = np.zeros(ratings.shape)\n",
    "    train = ratings.copy()\n",
    "    for user in xrange(ratings.shape[0]):\n",
    "        test_ratings = np.random.choice(ratings[user, :].nonzero()[0],\n",
    "                                        size=10, replace = False)\n",
    "        train[user, test_ratings] = 0\n",
    "        test[user, test_ratings] = ratings[user, test_ratings]\n",
    "    \n",
    "    assert(np.all(train * test) == 0)\n",
    "    return train, test\n",
    "\n",
    "train, test = train_test_split(ratings)\n",
    "        \n",
    "def slow_similarity(ratings, kind='user'):\n",
    "    if kind == 'user':\n",
    "        axmax = 0\n",
    "        axmin = 1\n",
    "    elif kind == 'item':\n",
    "        axmax = 1\n",
    "        axmin = 0\n",
    "    sim = np.zeros((ratings.shape[axmax], ratings.shape[axmax]))\n",
    "    for u in xrange(ratings.shape[axmax]):\n",
    "        for uprime in xrange(ratings.shape[axmax]):\n",
    "            rui_sqrd = 0.\n",
    "            ruprimei_sqrd = 0.\n",
    "            for i in xrange(ratings.shape[axmax]):\n",
    "                sim[u, uprime] = ratings[u, i] * ratings[uprime, i]\n",
    "                rui_sqrd += ratings[u, i] ** 2\n",
    "                ruprimei_sqrd += ratings[uprime, i] ** 2\n",
    "            sim[u, uprime] /= rui_sqrd * ruprimei_sqrd\n",
    "    return sim\n",
    "\n",
    "def fast_similarity(ratings, kind='user', epsilon=0.9):\n",
    "    # epsilon -> small number for handling dived-by-zero errors\n",
    "    if kind == 'user':\n",
    "        sim = ratings.dot(ratings.T) + epsilon\n",
    "    elif kind == 'item':\n",
    "        sim = ratings.T.dot(ratings) + epsilon\n",
    "    norms = np.array([np.sqrt(np.diagonal(sim))])\n",
    "    return (sim/norms/norms.T)\n",
    "\n",
    "user_similarity = fast_similarity(train, kind='user')\n",
    "item_similarity = fast_similarity(train, kind='item')\n",
    "#print(user_similarity[:4, :4])\n",
    "#print(item_similarity[:4, :4])\n",
    "\n",
    "def predict_slow_simple(ratings, similarity, kind='user'):\n",
    "    pred = np.zeros(ratings.shape)\n",
    "    if kind == 'user':\n",
    "        for i in xrange(ratings.shape[0]):\n",
    "            for j in xrange(ratings.shape[1]):\n",
    "                pred[i, j] = similarity[i, :].dot(ratings[:, j])\\\n",
    "                             /np.sum(np.abs(similarity[i, :]))\n",
    "        return pred\n",
    "    elif kind == 'item':\n",
    "        for i in xrange(ratings.shape[0]):\n",
    "            for j in xrange(ratings.shape[1]):\n",
    "                pred[i, j] = similarity[j, :].dot(ratings[i, :].T)\\\n",
    "                             /np.sum(np.abs(similarity[j, :]))\n",
    "\n",
    "        return pred\n",
    "        \n",
    "def predict_fast_simple(ratings, similarity, kind='user'):\n",
    "    if kind == 'user':\n",
    "        return similarity.dot(ratings) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif kind == 'item':\n",
    "        return ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])\n",
    "        \n",
    "from sklearn.metrics import mean_squared_error\n",
    "def get_mse(pred, actual):\n",
    "    #ignore nonzero terms\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return mean_squared_error(pred, actual)\n",
    "\n",
    "def get_rmse(pred, actual):\n",
    "    # Ignore nonzero terms.\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return mean_squared_error(pred, actual) ** 0.5\n",
    "\n",
    "item_prediction = predict_fast_simple(ratings, item_similarity, kind='item')\n",
    "user_prediction = predict_fast_simple(ratings, user_similarity, kind='user')\n",
    "\n",
    "print 'User-based CF MSE in train: ' + str(get_mse(user_prediction, train))\n",
    "print 'User-based CF rMSE in train: ' + str(get_rmse(user_prediction, train))\n",
    "print 'Item-based CF MSE in train: ' + str(get_mse(item_prediction, train))\n",
    "print 'Item-based CF rMSE in train: ' + str(get_rmse(item_prediction, train))\n",
    "print \n",
    "print 'User-based CF MSE in test: ' + str(get_mse(user_prediction, test))\n",
    "print 'User-based CF RMSE in test: ' + str(get_rmse(user_prediction, test))\n",
    "print 'Item-based CF MSE in test: ' + str(get_mse(item_prediction, test))\n",
    "print 'Item-based CF RMSE in test: ' + str(get_rmse(item_prediction, test))\n",
    "print 'cf mse: '+ str((get_rmse(user_prediction, test)+get_rmse(item_prediction, test))/2)\n",
    "\n",
    "### comment block starts here\n",
    "def predict_topk(ratings, similarity, kind='user', k=40):\n",
    "    pred = np.zeros(ratings.shape)\n",
    "    if kind == 'user':\n",
    "        for i in xrange(ratings.shape[0]):\n",
    "            top_k_users = [np.argsort(similarity[:,i])[:-k-1:-1]]\n",
    "            for j in xrange(ratings.shape[1]):\n",
    "                pred[i, j] = similarity[i, :][top_k_users].dot(ratings[:, j][top_k_users]) \n",
    "                pred[i, j] /= np.sum(np.abs(similarity[i, :][top_k_users]))\n",
    "    if kind == 'item':\n",
    "        for j in xrange(ratings.shape[1]):\n",
    "            top_k_items = [np.argsort(similarity[:,j])[:-k-1:-1]]\n",
    "            for i in xrange(ratings.shape[0]):\n",
    "                pred[i, j] = similarity[j, :][top_k_items].dot(ratings[i, :][top_k_items].T) \n",
    "                pred[i, j] /= np.sum(np.abs(similarity[j, :][top_k_items]))        \n",
    "    \n",
    "    return pred        \n",
    "def predict_fast_topk(ratings, similarity, kind='user', k=40):\n",
    "    \n",
    "    return\n",
    "#pred = predict_topk(train, user_similarity, kind='user', k=50)\n",
    "#print 'Top-k User-based CF MSE: ' + str(get_mse(pred, test))\n",
    "#pred = predict_topk(train, item_similarity, kind='item', k=15)\n",
    "#print 'Top-k Item-based CF MSE: ' + str(get_mse(pred, test))\n",
    "    \n",
    "def predict_nobias(ratings, similarity, kind='user'):\n",
    "    if kind == 'user':\n",
    "        user_bias = ratings.mean(axis=1)\n",
    "        ratings = (ratings - user_bias[:, np.newaxis]).copy()\n",
    "        pred = similarity.dot(ratings) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "        pred += user_bias[:, np.newaxis]\n",
    "    elif kind == 'item':\n",
    "        item_bias = ratings.mean(axis=0)\n",
    "        ratings = (ratings - item_bias[np.newaxis, :]).copy()\n",
    "        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])\n",
    "        pred += item_bias[np.newaxis, :]\n",
    "        \n",
    "    return pred\n",
    "#user_pred = predict_nobias(train, user_similarity, kind='user')\n",
    "#print 'Bias-subtracted User-based CF MSE: ' + str(get_mse(user_pred, test))\n",
    "#item_pred = predict_nobias(train, item_similarity, kind='item')\n",
    "#print 'Bias-subtracted Item-based CF MSE: ' + str(get_mse(item_pred, test))\n",
    "def predict_topk_nobias(ratings, similarity, kind='user', k=40):\n",
    "    pred = np.zeros(ratings.shape)\n",
    "    if kind == 'user':\n",
    "        user_bias = ratings.mean(axis=1)\n",
    "        ratings = (ratings - user_bias[:, np.newaxis]).copy()\n",
    "        for i in xrange(ratings.shape[0]):\n",
    "            top_k_users = [np.argsort(similarity[:,i])[:-k-1:-1]]\n",
    "            for j in xrange(ratings.shape[1]):\n",
    "                pred[i, j] = similarity[i, :][top_k_users].dot(ratings[:, j][top_k_users]) \n",
    "                pred[i, j] /= np.sum(np.abs(similarity[i, :][top_k_users]))\n",
    "        pred += user_bias[:, np.newaxis]\n",
    "    if kind == 'item':\n",
    "        item_bias = ratings.mean(axis=0)\n",
    "        ratings = (ratings - item_bias[np.newaxis, :]).copy()\n",
    "        for j in xrange(ratings.shape[1]):\n",
    "            top_k_items = [np.argsort(similarity[:,j])[:-k-1:-1]]\n",
    "            for i in xrange(ratings.shape[0]):\n",
    "                pred[i, j] = similarity[j, :][top_k_items].dot(ratings[i, :][top_k_items].T) \n",
    "                pred[i, j] /= np.sum(np.abs(similarity[j, :][top_k_items])) \n",
    "        pred += item_bias[np.newaxis, :]\n",
    "        \n",
    "    return pred   \n",
    " \n",
    "k_array = [5, 15, 30, 50, 100, 200]\n",
    "user_train_mse = []\n",
    "user_test_mse = []\n",
    "item_test_mse = []\n",
    "item_train_mse = []\n",
    "for k in k_array:\n",
    "    user_pred = predict_topk_nobias(train, user_similarity, kind='user', k=k)\n",
    "    item_pred = predict_topk_nobias(train, item_similarity, kind='item', k=k)\n",
    "    \n",
    "    user_train_mse += [get_mse(user_pred, train)]\n",
    "    user_test_mse += [get_mse(user_pred, test)]\n",
    "    \n",
    "    item_train_mse += [get_mse(item_pred, train)]\n",
    "    item_test_mse += [get_mse(item_pred, test)]  \n",
    "                      \n",
    "    \n",
    "idx_to_movie = {}\n",
    "with open('ml-100k/u.item', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        info = line.split('|')\n",
    "        idx_to_movie[int(info[0])-1] = info[4]\n",
    "        \n",
    "def top_k_movies(similarity, mapper, movie_idx, k=6):\n",
    "    return [mapper[x] for x in np.argsort(similarity[movie_idx,:])[:-k-1:-1]]   \n",
    "idx = 0 # Toy Story\n",
    "movies = top_k_movies(item_similarity, idx_to_movie, idx)\n",
    "for movie in movies:\n",
    "    print movie\n",
    "print '\\n'\n",
    "from sklearn.metrics import pairwise_distances\n",
    "# Convert from distance to similarity\n",
    "item_correlation = 1 - pairwise_distances(train.T, metric='correlation')\n",
    "item_correlation[np.isnan(item_correlation)] = 0.\n",
    "idx = 0 # Toy Story\n",
    "movies = top_k_movies(item_correlation, idx_to_movie, idx)\n",
    "for movie in movies:\n",
    "    print movie    \n",
    "print '\\n'                 \n",
    "    \n",
    "idx = 1 # GoldenEye\n",
    "movies = top_k_movies(item_similarity, idx_to_movie, idx)    \n",
    "for movie in movies:\n",
    "    print movie    \n",
    "print '\\n'\n",
    "idx = 1 # GoldenEye\n",
    "movies = top_k_movies(item_correlation, idx_to_movie, idx)\n",
    "for movie in movies:\n",
    "    print movie \n",
    "print '\\n'\n",
    "idx = 20 # Muppet Treasure Island\n",
    "movies = top_k_movies(item_similarity, idx_to_movie, idx)\n",
    "for movie in movies:\n",
    "    print movie    \n",
    "print '\\n'\n",
    "idx = 20 # Muppet Treasure Island\n",
    "movies = top_k_movies(item_correlation, idx_to_movie, idx)\n",
    "for movie in movies:\n",
    "    print movie    \n",
    "print '\\n'\n",
    "\n",
    "# comment block ends here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
